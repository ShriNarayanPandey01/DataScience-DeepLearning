{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q --upgrade keras\n",
        "!pip install -q --upgrade keras-nlp\n"
      ],
      "metadata": {
        "id": "ULtQ17LyvvkY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras_nlp\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = 'tensorflow'\n",
        "\n"
      ],
      "metadata": {
        "id": "20OFdVGvMWnt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keras.mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "OW3-3ZL7MzHY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "# !# Remove unsupervised examples\n",
        "!rm -r aclImdb/train/unsup\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mY1GYts7NIf6",
        "outputId": "fc9e1b29-a010-4630-84e4-6fd2d7eba55d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  7209k      0  0:00:11  0:00:11 --:--:-- 8895k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r aclImdb/train/unsup"
      ],
      "metadata": {
        "id": "XR4Z2ytzNcc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a708fb-3122-4e81-a072-ee6d3fba9987"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove 'aclImdb/train/unsup': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/train',\n",
        "    batch_size=32)\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    'aclImdb/test',\n",
        "    batch_size=32)\n"
      ],
      "metadata": {
        "id": "dmWSluN_Pi83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51acefd0-cd30-4519-ecc8-778ca47b60fe"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = keras_nlp.models.BertClassifier.from_preset(\n",
        "    'bert_tiny_en_uncased',\n",
        "    num_classes=2,\n",
        "    trainable=True)\n",
        "classifier.fit(train_ds,validation_data=test_ds,epochs=1)"
      ],
      "metadata": {
        "id": "eS__A95GP9eN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e1bda9f-912b-454e-c047-8382a73d60f1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/metadata.json...\n",
            "100%|██████████| 139/139 [00:00<00:00, 368kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/task.json...\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/config.json...\n",
            "100%|██████████| 507/507 [00:00<00:00, 1.18MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/model.weights.h5...\n",
            "100%|██████████| 16.8M/16.8M [00:00<00:00, 17.9MB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/preprocessor.json...\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/tokenizer.json...\n",
            "100%|██████████| 547/547 [00:00<00:00, 384kB/s]\n",
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/assets/tokenizer/vocabulary.txt...\n",
            "100%|██████████| 226k/226k [00:00<00:00, 940kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 63ms/step - loss: 0.5570 - sparse_categorical_accuracy: 0.6987 - val_loss: 0.3202 - val_sparse_categorical_accuracy: 0.8643\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b9c3077b220>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Preprocessor = keras_nlp.models.BertPreprocessor.from_preset('bert_tiny_en_uncased',sequence_length=512)\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "pmHLYOx3TCVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d5b04a-ee9f-4da7-a812-29056dc3be61"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/preprocessor.json...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VgA9MqyvZxVE"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_cached = train_ds.map(Preprocessor,tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",
        "test_cached = test_ds.map(Preprocessor,tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "XoapanqEZa1A"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = keras_nlp.models.BertClassifier.from_preset(\n",
        "    'bert_tiny_en_uncased',\n",
        "    num_classes=2,\n",
        "    preprocessor = None)\n",
        "classifier.fit(train_cached,validation_data=test_cached,epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tGtv4NdZ7ym",
        "outputId": "7ab116af-7052-48a1-c257-de25e6c35178"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/task.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 52ms/step - loss: 0.5599 - sparse_categorical_accuracy: 0.6916 - val_loss: 0.3148 - val_sparse_categorical_accuracy: 0.8670\n",
            "Epoch 2/3\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 39ms/step - loss: 0.3051 - sparse_categorical_accuracy: 0.8728 - val_loss: 0.2929 - val_sparse_categorical_accuracy: 0.8788\n",
            "Epoch 3/3\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 26ms/step - loss: 0.2429 - sparse_categorical_accuracy: 0.9036 - val_loss: 0.3077 - val_sparse_categorical_accuracy: 0.8771\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b9baf149720>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = keras_nlp.models.BertTokenizer.from_preset('bert_tiny_en_uncased')\n",
        "tokenizer([\"i love this project\"])"
      ],
      "metadata": {
        "id": "4jOt3idlaO05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2556941-700b-4c58-ddad-d8d7fdcee823"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[1045, 2293, 2023, 2622]]>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "packer = keras_nlp.layers.MultiSegmentPacker(\n",
        "    start_value=tokenizer.cls_token_id,\n",
        "    end_value=tokenizer.sep_token_id,\n",
        "    sequence_length=64)\n",
        "\n",
        "def preprocessor(x,y):\n",
        "  token_ids,segment_ids = packer(tokenizer(x))\n",
        "  print(token_ids)\n",
        "  print(segment_ids)\n",
        "  x= {\n",
        "       \"token_ids\":token_ids,\n",
        "       \"segment_ids\":segment_ids,\n",
        "       \"padding_mask\":token_ids!=0\n",
        "  }\n",
        "  return x,y"
      ],
      "metadata": {
        "id": "uCVwwPTY1OyQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text , label in train_ds.take(1):\n",
        "  x,y=preprocessor(text,label)\n",
        "  print(y)"
      ],
      "metadata": {
        "id": "SH0LeeFo2jqc",
        "outputId": "e5869dc7-b2fc-43e3-a926-168a2b451eca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 101 1045 2079 ... 2039 1998  102]\n",
            " [ 101 1045 2081 ... 2003 2205  102]\n",
            " [ 101 2055 1996 ... 1056 2342  102]\n",
            " ...\n",
            " [ 101 2045 2064 ... 2024 2895  102]\n",
            " [ 101 2023 2003 ... 1007 2023  102]\n",
            " [ 101 2057 2018 ... 5019 1045  102]], shape=(32, 64), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]], shape=(32, 64), dtype=int32)\n",
            "tf.Tensor([0 0 0 0 0 1 1 1 0 0 1 1 1 0 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 1 1 0], shape=(32,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_preprocessed = train_ds.map(preprocessor,tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",
        "test_preprocessed = test_ds.map(preprocessor,tf.data.AUTOTUNE).cache().prefetch(tf.data.AUTOTUNE)\n",
        "classifier = keras_nlp.models.BertClassifier.from_preset(\n",
        "    'bert_tiny_en_uncased',\n",
        "    num_classes=2,\n",
        "    preprocessor = None)\n",
        "classifier.fit(train_preprocessed,validation_data=test_preprocessed,epochs=3)"
      ],
      "metadata": {
        "id": "dvCPOAKT4TXz",
        "outputId": "89a8f001-d5a8-423c-fdd0-ed03a11a7c92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"multi_segment_packer_9_1/RaggedToTensor/RaggedTensorToTensor:0\", shape=(None, 64), dtype=int32, device=/device:CPU:*)\n",
            "Tensor(\"multi_segment_packer_9_1/RaggedToTensor_1/RaggedTensorToTensor:0\", shape=(None, 64), dtype=int32, device=/device:CPU:*)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/bert/keras/bert_tiny_en_uncased/2/download/task.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"multi_segment_packer_9_1/RaggedToTensor/RaggedTensorToTensor:0\", shape=(None, 64), dtype=int32, device=/device:CPU:*)\n",
            "Tensor(\"multi_segment_packer_9_1/RaggedToTensor_1/RaggedTensorToTensor:0\", shape=(None, 64), dtype=int32, device=/device:CPU:*)\n",
            "Epoch 1/3\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 49ms/step - loss: 0.6315 - sparse_categorical_accuracy: 0.6294 - val_loss: 0.5082 - val_sparse_categorical_accuracy: 0.7470\n",
            "Epoch 2/3\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 28ms/step - loss: 0.4864 - sparse_categorical_accuracy: 0.7709 - val_loss: 0.4895 - val_sparse_categorical_accuracy: 0.7608\n",
            "Epoch 3/3\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 0.4247 - sparse_categorical_accuracy: 0.8068 - val_loss: 0.5156 - val_sparse_categorical_accuracy: 0.7550\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b9b74318fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BRyAwgNL6TBN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}