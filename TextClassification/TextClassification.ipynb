{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TCLSspS2rXf9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import re\n",
        "import shutil\n",
        "import string\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n",
        "dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url,\n",
        "                                    untar=True, cache_dir='.',\n",
        "                                    cache_subdir='')\n",
        "dataset_dir = os.path.join(os.path.dirname(dataset),'aclImdb')\n",
        "os.listdir(dataset_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlUm834EEYDu",
        "outputId": "9daffb91-04be-4916-d755-ebe51a29b8ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "84125825/84125825 [==============================] - 3s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['train', 'README', 'imdb.vocab', 'imdbEr.txt', 'test']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = os.path.join(dataset_dir, 'train')\n",
        "os.listdir(train_dir)"
      ],
      "metadata": {
        "id": "i8j6k7AhG_eG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f293125-5281-4c5e-b92c-e3ee59f79aee"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['urls_neg.txt',\n",
              " 'urls_unsup.txt',\n",
              " 'unsupBow.feat',\n",
              " 'pos',\n",
              " 'unsup',\n",
              " 'urls_pos.txt',\n",
              " 'labeledBow.feat',\n",
              " 'neg']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_file = os.path.join(train_dir,\"pos/1181_9.txt\")\n",
        "with open(sample_file) as f:\n",
        "  print(f.read())"
      ],
      "metadata": {
        "id": "54Hs-v88Mppa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebf7a034-068d-4a8a-8667-16404988baa5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rachel Griffiths writes and directs this award winning short film. A heartwarming story about coping with grief and cherishing the memory of those we've loved and lost. Although, only 15 minutes long, Griffiths manages to capture so much emotion and truth onto film in the short space of time. Bud Tingwell gives a touching performance as Will, a widower struggling to cope with his wife's death. Will is confronted by the harsh reality of loneliness and helplessness as he proceeds to take care of Ruth's pet cow, Tulip. The film displays the grief and responsibility one feels for those they have loved and lost. Good cinematography, great direction, and superbly acted. It will bring tears to all those who have lost a loved one, and survived.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "remove_dir = os.path.join(train_dir,\"unsup\")\n",
        "shutil.rmtree(remove_dir)"
      ],
      "metadata": {
        "id": "xc_jvo_2Wjco"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=42\n",
        "seed=42\n",
        "raw_train_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='training',\n",
        "    seed=seed\n",
        ")\n",
        "print(raw_train_ds.take(1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yI7U9wRYDs9",
        "outputId": "db589d99-b107-4b7f-89d5-d846ac516ea0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "<_TakeDataset element_spec=(TensorSpec(shape=(None,), dtype=tf.string, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for text_batch ,label_batch in raw_train_ds.take(1):\n",
        "  for i in range(3):\n",
        "    print(\"review\",text_batch.numpy()[i])\n",
        "    print(\"label\",label_batch.numpy()[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mId-TSd4ZBJc",
        "outputId": "e8b006fd-31ed-46da-8ad0-f5225623eecc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "review b\"Rob Estes, Josie Bisset and a crap load of kids that look nothing like either of them.<br /><br />Basically, Rob and Josie have a shotgun wedding on a drunken night during a Vegas vacation. They each come home to find that their respective children already know of the nuptials due to tabloid-like not-so-fodder. They, Rob and Josie, move both of them and their eight kids into one or the other's house.<br /><br />Rob builds furniture, I think, which is close enough to Frank Lambert's (Patrick Duffy) construction job on the much similar Step by Step to warrant eternal mockage.<br /><br />Josie is some sort of cookie-making queen, though it doesn't look like she makes any of the cookies. Not close enough to Carol Foster's (Suzanne Somers)hairdressing job to warrant likeness mockage, but hilariously preposterous enough to warrant atrocity mockage.<br /><br />Unlike Step by Step, they were a couple before the vacation and actually knew one another's last names, or so one assumes if their serious enough about a relationship to take a trip together.<br /><br />Anyhow, there are eight kids; Moira, Sandy, Jeff, Lily, Daisy, Nathan, Andrew L. and Andrew B. I, personally, think they should've just called the younger Andrew 'Andy'.<br /><br />There's a lot of product placement, particularly for Soup at Hand (Which is disgusting) and Listerine Pocket Packs. There are also some stupid, senseless moments. It's also not a great film to promote happy families.<br /><br />But, hey! Rob Estes! This concludes my review of 'Step By Step... on some really bad drugs.' Watch it for Rob Estes and his pretty!eyes. There are some great pretty!eyes shots.\"\n",
            "label 1\n",
            "review b\"I was really looking forward to seeing this film, but after watching it I was really disappointed. The best bit was when Stephen King was in it. Rober John Berk cannot act to save his life and neither can any of the others. A few of the performances even made me laugh out loud! The film was was not as I imagined it, after reading the book which was awesome, I imagined it darker and a lot scarier. If i was Stephen, I would be really mad!<br /><br />I don't know why they changed the ending, I thought the ending of the book was very good. If you just found out the pie killed your daughter, you wouldn't feed it to anyone else would you?!<br /><br />Book was so much better!\"\n",
            "label 0\n",
            "review b'What a lovely heart warming television movie. The story tells of a little five year old girl who has lost her daddy and finds it impossible to cope. Her mother is also very distressed ..only a miracle can alleviate their unhappiness.Which all viewers hope will materialise. Samantha Mathis is brilliant as the little girl\\'s mum ,as she was as the nanny in\" Jack and Sarah\",worth watching if you like both Samantha Mathis and happy; year tear jerking movies! Ellen Burstyn is, as, always a delightful grandmother in this tender and magnificently acted movie. Jodelle Ferland (the little five year old) is charming and a most convincing young actress. The film is based on a true story which makes it so touching.\"Mermaid\" is a tribute to the milk of human kindness which is clearly illustrated and clearly is still all around us in this difficult world we live in. \"Mermaid\" gives us all hope ,by realising that there a lot of lovely people in the world with lot\\'s of love to give. James Robson Glasgow Scotland U.K.'\n",
            "label 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Label 0 corresponds to\", raw_train_ds.class_names[0])\n",
        "print(\"Label 1 corresponds to\", raw_train_ds.class_names[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbvHt_OiZ4B2",
        "outputId": "b97affe8-ef34-4ede-f161-deaec1b29e27"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label 0 corresponds to neg\n",
            "Label 1 corresponds to pos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_validation_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train\",\n",
        "    batch_size=batch_size,\n",
        "    validation_split=0.2,\n",
        "    subset='validation',\n",
        "    seed=seed\n",
        ")\n",
        "for text_batch ,label_batch in raw_validation_ds.take(1):\n",
        "  for i in range(3):\n",
        "    print(\"review\",text_batch.numpy()[i])\n",
        "    print(\"label\",label_batch.numpy()[i])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBst8sbXdbip",
        "outputId": "f87a5d5c-aa5f-452e-caea-6942a8574c45"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "review b\"Quite one of the worst films I have ever seen. Terrible acting, laughable 'action' (it's clear that the cars are travelling slowly), atrocious script, hideously unsatisfying ending and incompetent direction make a hash of a movie. We know Judge Reinhold is a fine actor, but he should be ashamed of this detritus. There is no great tension within the car and, when the characters stumble upon moments of hope, they laugh like inane banshees for some reason, even 'high five-ing' when they see the bridge lowered!<br /><br />Also, the chain of events that lead these people to share the same car strains credibility. Apparently based on true events, though? If that's the case, truth is evidently stranger than fiction! Unfortunate then, that it was portrayed in such an inept manner.\"\n",
            "label 0\n",
            "review b'Opening scene \\'explains\\' why Hurt is later \\'immune\\' to the \\'Contaminated Man\\'. Too bad it doesn\\'t explain anything else: How did he get whatever he \\'caught\\'/what was it/why does it work so fast. Then we go to \"Present Day Budapest\". OK, was the opener in the past or the future? It turns out to be the past, of course, but for a minute it looks just as likely to be the nd of the movie moved to the beginning. Sorry, I should have paid closer attention, huh? Or maybe it\\'s just badly done. Then a lot of confusion about the different jobs he\\'s had in related fields, and finally a mention about how he should have died from the original experiment the n s a did on him. Aha! So the n s a and private industry got together to poison one of their top guys to watch the effects? He must have been one of the top guys, he\\'s friends with the c e o of the Chemical company, for God sakes. Then there\\'s the substance itself: Technically a poison, but it mutates in immune \\'carriers\\', so we can have whatever we want; a poison, a disease, an allergic reaction, all very different things in real life. Magically, it\\'s not contagious from one dying victim to another, only from the carrier. How convenient. Then there\\'s the h a z m a t protocol: They jump into a situation without having any idea what\\'s in store, or how prepare for it. Did the producers not have enough money to show a proper wash-down after the crew just left the scene of a deadly unknown substance? I kept thinking Hurt was going to die from bad cleanup technique, and the open scene would turn out to be the closer after all.'\n",
            "label 0\n",
            "review b\"Quite possibly. How Francis Veber, one of the best comedy directors in the world (at least when sticking to his native France), managed to turn in a film so completely unwatchable is beyond the reason of mere mortal man to discern. It's not just that the characters are so unlikeable or that the film is so utterly devoid of even the lowest form of wit: it's genuinely physically painful to watch, such an endless parade of inept writing, acting and film-making that you cannot believe this is the work of experienced - and talented - filmmakers. For once the near-eternity spent in the cutting room and on the shelf before its blink-and-you'll-miss-it theatrical release tells the whole story. What were they thinking?\"\n",
            "label 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_test_ds = tf.keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\",\n",
        "    batch_size=batch_size\n",
        ")\n",
        "for text_batch ,label_batch in raw_test_ds.take(1):\n",
        "  for i in range(3):\n",
        "    print(\"review\",text_batch.numpy()[i])\n",
        "    print(\"label\",label_batch.numpy()[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_wPKS6Le9h4",
        "outputId": "4072a7c0-3e7d-444b-8d87-46eb7850abea"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "review b'My wife is a mental health therapist and we watched it from beginning to end. I am the typical man and can not stand chick flicks, but this movie is unbelievable. If you want to see what it is like for someone who is going through these type of struggles, this is the movie for you. As I watched it I found myself feeling sorry for him and others like him. <br /><br />***Spoiler*** Plus the fact that all the individuals in the movie including the people in the mental institution were the actual people in real life made it that more real.<br /><br />A must see for someone in the mental health profession!'\n",
            "label 1\n",
            "review b'This version of Mansfield Park, while being extremely accurate to the novel lacked the compassion I felt for Fanny which is crucial and central to this Jane Austen story. This was due to the total lack of acting ability by the actress, Sylvestra Le Touzel. She had no appeal and at times appeared to be either lost in space or out of her depth. The scene she has with her uncle where she breaks down in hysterics was hysterical. She badly overplayed that crucial scene and I actually felt sorry that Henry Crawford ever cared for her.<br /><br />The polar opposite is the portrayal of Mary Crawford by Jackie Smith- Wood. What a wonderful actress, in a very difficult part to make that character witty and self-centered, selfish yet vulnerable to love.<br /><br />I have always loved Fanny. She is mild mannered but with an implacable sense of what is right, and who she thinks is worthy of respect and admiration. The Fanny in this adaptation is too meek and subservient with hardly a thought of her own until near the end of the series. As much as I wanted to like this Fanny....I just could not. <br /><br />I suggest skipping this version of Mansfield Park for the real thing...the Novel. Fanny will not disappoint...you will Love Her!'\n",
            "label 0\n",
            "review b'Rarely have I seen a work of literature translated so badly to the screen. The hysterical cast of b-movie and sitcom extras simply make the characters seem like bad Jewish stereotypes. The worst of all is Melissa Gilbert, who you hate from scene one and never develop any sympathy for. Performances like this should be noted and used against actors who wish to work again. All in all, a seedy, low-budget made-for-TV film of the sort that gives made-for-TV films a bad name.'\n",
            "label 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  stripped_html = tf.strings.regex_replace(lowercase, '<br />', ' ')\n",
        "  return tf.strings.regex_replace(stripped_html,\n",
        "                                  '[%s]' % re.escape(string.punctuation),\n",
        "                                  '')"
      ],
      "metadata": {
        "id": "zDjfbRLOgC-t"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorized_layer = layers.TextVectorization(\n",
        "    standardize = custom_standardization,\n",
        "    max_tokens = 10000,\n",
        "    output_mode = 'int',\n",
        "    output_sequence_length=255\n",
        ")"
      ],
      "metadata": {
        "id": "-Mip4_fig86r"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_text = raw_train_ds.map(lambda x, y: x)\n",
        "print(train_text.take(1))\n",
        "vectorized_layer.adapt(train_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTw7isQOhrVF",
        "outputId": "79373bdc-c69d-437b-db86-5e407b82cf46"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_TakeDataset element_spec=TensorSpec(shape=(None,), dtype=tf.string, name=None)>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorize_text(text, label):\n",
        "  text = tf.expand_dims(text, -1)\n",
        "  return vectorized_layer(text), label\n",
        "\n",
        "text_batch, label_batch = next(iter(raw_train_ds))\n",
        "first_review, first_label = text_batch[0], label_batch[0]\n",
        "print(\"Review\", first_review)\n",
        "print(\"Label\", raw_train_ds.class_names[first_label])\n",
        "print(\"Vectorized review\", vectorize_text(first_review, first_label))\n",
        "\n",
        "print(\"1287 ---> \",vectorized_layer.get_vocabulary()[1287])\n",
        "print(\" 313 ---> \",vectorized_layer.get_vocabulary()[313])\n",
        "print('Vocabulary size: {}'.format(len(vectorized_layer.get_vocabulary())))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmG0nokdjAhX",
        "outputId": "6e6394e7-caa0-40ec-ebc2-a6a7e41bb5a0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review tf.Tensor(b\"Live Feed is set in some unnamed Chinese/Japanese Asian district somewhere as five American friends, Sarah (Ashley Schappert), Emily (Taayla Markell), Linda (Caroline Chojnacki), Mike (Lee Tichon) & Darren (Rob Scattergood) are enjoying a night on the town & taking in the sights. After a scuffle in a bar with a Japanese Triad boss (Stephen Chang) they decide to check out a porno theatre, as you would. Inside they are separated & quickly find out that the place belongs to the Triad boss who uses it to torture & kill people for reasons which aren't made clear. Can local boy Miles (Kevan Ohtsji) save them?<br /><br />This Canadian production was co-written, produced & directed by Ryan Nicholson who also gets a prosthetic effects designer credit as well, one has to say that Live Feed is another pretty poor low budget shot on a camcorder type horror film that seems to exist only to cash in on the notoriety & success of Hostel (2005) & the mini craze for 'torture porn' as it's become known. According the IMDb's 'Trivia' section for Live Feed writer & director Nicholson wrote it after hearing about certain activities taking place in live sex theatres, for my money I reckon he wrote it after watching Hostel! The script is pretty poor, there is no basic reason given as to why this porno theatre has a big fat ugly freak dressed in bondage gear lurking around torturing & killing people, none. Was it for the Triads? Was it for his pleasure? Was it to make snuff films to sell? Some sort of explanation would have been nice. Also why did he turn on the Triad boss at the end? If your looking for a film with a coherent story then forget about Live Feed. It seemed to me to be some sort of uneasy misjudged mix of sex, S&M, horror, torture, gore & action films which doesn't come off. I mean just setting a horror film in a porn theatre isn't automatically going to make your film any good, there still needs to be a decent script & story, right? The character's were fairly poor clich\\xc3\\xa9s & some of their actions & motivations were more than a little bit questionable. It moves along at a reasonable pace, it's fairly sleazy mixing gore, sex & nudity but it does look cheap which lessens the effect.<br /><br />Director Nicholson doesn't do anything special here, the editing is choppy & annoying, he seems to think lighting almost every scene with neon lights is a good idea & the film has a cheap look about it. Available in both 'R' & 'Unrated' versions I saw the shorter cut 'R' version which really isn't that gory but I am prepared to give the benefit of the doubt to the 'Unrated' version & say that it might be much, much gorier but I can't say for sure. There's a fair amount of nudity too if that's your thing. I wouldn't say there's much of an atmosphere or many scares here because there isn't & aren't respectively although it does have a sleazy tone in general which is something it has going for it I suppose.<br /><br />Technically Live Feed isn't terribly impressive, the blood looks a little too watery for my liking & entire scenes bathed in annoying neon lights sometimes makes it hard to tell whats happening, it to often looks like it was shot on a hand-held camcorder & the choppy editing at least on the 'R' rated version is at times an annoying mess. Shot on location in an actual porn theatre somewhere in Vancouver in Canada. The acting is poor, sometimes I couldn't tell if the actresses in this were supposed to be crying or laughing...<br /><br />Live Feed is not a film I would recommend anyone to rush out & buy or rent, I didn't think much of it with it's very weak predictable storyline lacking exposition & which goes nowhere, poor acting & less than impressive gore (at least in the 'R' rated cut anyway). Watch either Hostel films again or instead as they are superior.\", shape=(), dtype=string)\n",
            "Label neg\n",
            "Vectorized review (<tf.Tensor: shape=(1, 255), dtype=int64, numpy=\n",
            "array([[ 419, 4429,    7,  286,    8,   46, 9200,    1, 2204, 7543, 1116,\n",
            "          14,  713,  312,  335, 2697, 4907,    1, 3676,    1,    1, 4418,\n",
            "        9144,    1, 1971,  818,    1, 4739, 1983,    1,   23, 2876,    4,\n",
            "         313,   20,    2,  509,  667,    8,    2, 7173,  101,    4,    1,\n",
            "           8,    4, 1483,   16,    4,  864,    1, 1327, 1631,    1,   34,\n",
            "        1170,    6,  793,   44,    4, 4412, 1705,   14,   22,   59,  965,\n",
            "          34,   23, 6926,  906,  163,   44,   12,    2,  265, 3135,    6,\n",
            "           2,    1, 1327,   36, 1058,    9,    6, 1674,  512,   79,   15,\n",
            "         966,   60,  691,   90,  809,   68,  690,  436, 2059,    1,    1,\n",
            "         586,   93,   11, 2371,  359,   13, 8919, 1118,  523,   32, 2390,\n",
            "        4539,   36,   77,  201,    4,    1,  300, 5280, 1080,   14,   73,\n",
            "          28,   43,    6,  131,   12,  419, 4429,    7,  154,  179,  342,\n",
            "         481,  416,  315,   20,    4, 5549,  595,  191,   19,   12,  180,\n",
            "           6, 1790,   61,    6, 2349,    8,   20,    2,    1,  981,    5,\n",
            "        7518, 3474,    2, 4199,    1,   15, 1674, 1590,   14,   29,  394,\n",
            "         630, 1668,    2, 9539, 5638, 2571,   15,  419, 4429,  787,  172,\n",
            "        4539, 1077,    9,  101, 2125,   42,  780, 5226,  667,  265,    8,\n",
            "         419,  388, 7448,   15,   54,  279,   10,    1,   27, 1077,    9,\n",
            "         101,  146, 7518,    2,  224,    7,  179,  342,   47,    7,   57,\n",
            "        1076,  273,  340,   14,    6,  133,   11, 4412, 1705,   43,    4,\n",
            "         199, 1861, 1519, 4249, 2037,    8, 5551, 5678, 7080,  183,    1,\n",
            "         846,   79,  577,   13,    9,   15,    2,    1,   13,    9,   15,\n",
            "          24, 1673,   13,    9,    6,   96, 6586,   94,    6, 2142,   46,\n",
            "         425,    5]])>, <tf.Tensor: shape=(), dtype=int32, numpy=0>)\n",
            "1287 --->  silent\n",
            " 313 --->  night\n",
            "Vocabulary size: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = raw_train_ds.map(vectorize_text)\n",
        "val_ds = raw_validation_ds.map(vectorize_text)\n",
        "test_ds = raw_test_ds.map(vectorize_text)"
      ],
      "metadata": {
        "id": "mqgqt6XunoYj"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "PTe72th4v-26"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    layers.Embedding(10000,16),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.GlobalAveragePooling1D(),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Dense(1,activation='sigmoid')\n",
        "]\n",
        ")"
      ],
      "metadata": {
        "id": "iiLKQorvwIxK"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnrQIQvuzvM2",
        "outputId": "d8ac7bca-98a6-4581-bf8f-e1b580347397"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, None, 16)          160000    \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, None, 16)          0         \n",
            "                                                                 \n",
            " global_average_pooling1d_1  (None, 16)                0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 160017 (625.07 KB)\n",
            "Trainable params: 160017 (625.07 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss = losses.BinaryCrossentropy(),\n",
        "              optimizer='adam',\n",
        "              metrics=[tf.metrics.BinaryAccuracy(threshold=0.5)])"
      ],
      "metadata": {
        "id": "xPpyjGRd0HMC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "         train_ds,\n",
        "         validation_data=val_ds,\n",
        "         epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5GHlZn20qmA",
        "outputId": "56cf11d8-ddcb-4109-9a79-81d262f6b318"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "477/477 [==============================] - 9s 15ms/step - loss: 0.6738 - binary_accuracy: 0.6820 - val_loss: 0.6385 - val_binary_accuracy: 0.7670\n",
            "Epoch 2/10\n",
            "477/477 [==============================] - 4s 9ms/step - loss: 0.5835 - binary_accuracy: 0.7871 - val_loss: 0.5380 - val_binary_accuracy: 0.8098\n",
            "Epoch 3/10\n",
            "477/477 [==============================] - 4s 8ms/step - loss: 0.4866 - binary_accuracy: 0.8299 - val_loss: 0.4585 - val_binary_accuracy: 0.8382\n",
            "Epoch 4/10\n",
            "477/477 [==============================] - 5s 10ms/step - loss: 0.4159 - binary_accuracy: 0.8561 - val_loss: 0.4050 - val_binary_accuracy: 0.8512\n",
            "Epoch 5/10\n",
            "477/477 [==============================] - 4s 8ms/step - loss: 0.3674 - binary_accuracy: 0.8712 - val_loss: 0.3699 - val_binary_accuracy: 0.8610\n",
            "Epoch 6/10\n",
            "477/477 [==============================] - 4s 8ms/step - loss: 0.3344 - binary_accuracy: 0.8815 - val_loss: 0.3462 - val_binary_accuracy: 0.8666\n",
            "Epoch 7/10\n",
            "477/477 [==============================] - 5s 10ms/step - loss: 0.3086 - binary_accuracy: 0.8887 - val_loss: 0.3296 - val_binary_accuracy: 0.8706\n",
            "Epoch 8/10\n",
            "477/477 [==============================] - 4s 8ms/step - loss: 0.2884 - binary_accuracy: 0.8956 - val_loss: 0.3168 - val_binary_accuracy: 0.8736\n",
            "Epoch 9/10\n",
            "477/477 [==============================] - 4s 8ms/step - loss: 0.2713 - binary_accuracy: 0.9024 - val_loss: 0.3073 - val_binary_accuracy: 0.8752\n",
            "Epoch 10/10\n",
            "477/477 [==============================] - 4s 9ms/step - loss: 0.2551 - binary_accuracy: 0.9092 - val_loss: 0.3005 - val_binary_accuracy: 0.8774\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_ds)\n",
        "\n",
        "print(\"Loss: \", loss)\n",
        "print(\"Accuracy: \", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF8mx9vT004p",
        "outputId": "9f2ef58e-85f8-49ee-d45c-004aa5039dd8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "596/596 [==============================] - 6s 10ms/step - loss: 0.3179 - binary_accuracy: 0.8718\n",
            "Loss:  0.31793540716171265\n",
            "Accuracy:  0.8717600107192993\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "history_dict.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBD26-2v1rF-",
        "outputId": "34bfaa68-9fec-4a9d-8b84-6ab2408f4d7e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['loss', 'binary_accuracy', 'val_loss', 'val_binary_accuracy'])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "export_model = tf.keras.Sequential([\n",
        "  vectorized_layer,\n",
        "  model,\n",
        "  layers.Activation('sigmoid')\n",
        "])\n",
        "\n",
        "export_model.compile(\n",
        "    loss=losses.BinaryCrossentropy(from_logits=False), optimizer=\"adam\", metrics=['accuracy']\n",
        ")\n",
        "\n",
        "loss, accuracy = export_model.evaluate(raw_test_ds)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meajiglI1wWM",
        "outputId": "31ad78c7-7bb7-438d-c46e-7473d953b5ea"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "596/596 [==============================] - 4s 7ms/step - loss: 0.5940 - accuracy: 0.5000\n",
            "0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yH2nyr9v2G_G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}